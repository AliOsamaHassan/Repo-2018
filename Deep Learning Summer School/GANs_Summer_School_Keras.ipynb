{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative Adversarial Networks in Keras\n",
    "\n",
    "First let's import all the necessary libraries\n",
    "In this case Keras is running in a Tensorflow backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from keras.layers import Input, Dense, Lambda, Merge\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Reshape\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
    "import random\n",
    "from keras.optimizers import SGD\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, each digit type is adjusted to 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following step selects a small sample from MNIST so that you can do the computation even without a GPU\n",
    "After that, we add noise to data, using a random normal distribution with mean equal to zero and standard deviation equal to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=60\n",
    "\n",
    "x_train=x_train[0:n]\n",
    "x_test=x_test[n:n+n]\n",
    "\n",
    "noise_factor = 0.1\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape inputs for the Neural Network that will be composed of real data and data with noise addded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train=x_train.reshape((n,28,28,1))\n",
    "x_test=x_test.reshape((n,28,28,1))\n",
    "x_train_noisy = x_train_noisy.reshape((n,28,28,1))\n",
    "x_test_noisy = x_test_noisy.reshape((n,28,28,1))\n",
    "\n",
    "x_train_noisy=np.concatenate([x_train_noisy,x_train]).reshape(2*n,28,28,1)\n",
    "x_train=np.concatenate([x_train,x_train]).reshape(2*n,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select a random sample from real data + noisy data and get one-hot encodes for y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(200)\n",
    "sel=random.sample(range(0,x_train.shape[0]), 100)\n",
    "y_train=pd.get_dummies(y_train[sel])\n",
    "x_train_noisy=x_train_noisy[sel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "nb_classes = 10\n",
    "img_rows, img_cols = 28, 28\n",
    "nb_filters = 32\n",
    "pool_size = (2, 2)\n",
    "kernel_size = (3, 3)\n",
    "input_shape=(28,28,1)\n",
    "learning_rate = 0.008\n",
    "decay_rate = 5e-5\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we develop the Generative part of the GAN using Keras and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 28,353\n",
      "Trainable params: 28,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=learning_rate,momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "generator = Model(input_img, decoded)\n",
    "generator.compile(loss='mean_squared_error', optimizer=sgd,metrics = ['accuracy'])\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the Discriminator part of the GAN, using model.add instead of x=layer(x) to diversify our knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 600,810\n",
      "Trainable params: 600,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1]),\n",
    "                        padding='valid',\n",
    "                        input_shape=input_shape))\n",
    "discriminator.add(Activation('relu'))\n",
    "discriminator.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "discriminator.add(Activation('relu'))\n",
    "discriminator.add(MaxPooling2D(pool_size=pool_size))\n",
    "discriminator.add(Dropout(0.25))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(128))\n",
    "discriminator.add(Activation('relu'))\n",
    "discriminator.add(Dropout(0.5))\n",
    "discriminator.add(Dense(10))\n",
    "discriminator.add(Activation('softmax'))\n",
    "discriminator.compile(loss='categorical_crossentropy', optimizer=sgd,metrics = ['accuracy'])\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we'll create a function that will allow us to freeze the training of the Generator (OR NOT) so that we can try different update strategies with Discriminator and Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for k in net.layers:\n",
    "       k.trainable = val\n",
    "trainable(generator, False)\n",
    "\n",
    "gan_input = Input(batch_shape=(None, 28,28,1))\n",
    "\n",
    "gan_level2 = discriminator(generator([gan_input]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compile the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GAN = Model(gan_input, gan_level2)\n",
    "GAN.compile(loss='mean_squared_error', optimizer=sgd,metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we will update Discriminator and Generator asynchronously in the proportion 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator epoch 0\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.4123 - acc: 0.4900     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.3655 - acc: 0.4500     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0930 - acc: 0.1300     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0928 - acc: 0.1300     \n",
      "Discriminator epoch 1\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.4432 - acc: 0.4100     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.3586 - acc: 0.4200     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0923 - acc: 0.2000     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0933 - acc: 0.1200     \n",
      "Discriminator epoch 2\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.4117 - acc: 0.5000     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.4661 - acc: 0.4500     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0930 - acc: 0.1400     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0914 - acc: 0.0900     \n",
      "Discriminator epoch 3\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.5457 - acc: 0.4700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.3836 - acc: 0.4300     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0905 - acc: 0.1300     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0902 - acc: 0.1000     \n",
      "Discriminator epoch 4\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.3411 - acc: 0.5000     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.4934 - acc: 0.5000     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0945 - acc: 0.0800     \n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s - loss: 0.0894 - acc: 0.1600     \n",
      "Discriminator epoch 21\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.3592 - acc: 0.4100     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.4187 - acc: 0.4400     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0896 - acc: 0.1500     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0892 - acc: 0.1800     \n",
      "Discriminator epoch 22\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.2738 - acc: 0.4700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.2821 - acc: 0.5000     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0898 - acc: 0.1700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0900 - acc: 0.1400     \n",
      "Discriminator epoch 23\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.3358 - acc: 0.4800     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.2466 - acc: 0.5400     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0894 - acc: 0.1400     \n",
      "Discriminator epoch 24\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.1464 - acc: 0.4800     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.1253 - acc: 0.4800     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0893 - acc: 0.1500     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0894 - acc: 0.1400     \n",
      "Discriminator epoch 25\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.3554 - acc: 0.4300     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.2521 - acc: 0.4900     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0908 - acc: 0.1000     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0907 - acc: 0.0900     \n",
      "Discriminator epoch 26\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.3031 - acc: 0.5100     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.2490 - acc: 0.4500     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0903 - acc: 0.1000     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0897 - acc: 0.1800     \n",
      "Discriminator epoch 27\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.0919 - acc: 0.5500     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.2463 - acc: 0.5000     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0906 - acc: 0.1200     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0900 - acc: 0.1700     \n",
      "Discriminator epoch 28\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.1360 - acc: 0.4900     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.3069 - acc: 0.4900     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0897 - acc: 0.1800     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0901 - acc: 0.1500     \n",
      "Discriminator epoch 29\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.2122 - acc: 0.5300     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.1863 - acc: 0.4800     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1800     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0896 - acc: 0.1800     \n",
      "Discriminator epoch 30\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.2901 - acc: 0.5000     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.1274 - acc: 0.5800     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1700     \n",
      "Discriminator epoch 31\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.1538 - acc: 0.5300     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.1724 - acc: 0.4800     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0896 - acc: 0.1600     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0896 - acc: 0.1500     \n",
      "Discriminator epoch 32\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.1579 - acc: 0.5300     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.2169 - acc: 0.4900     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0897 - acc: 0.1500     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1600     \n",
      "Discriminator epoch 33\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.3336 - acc: 0.4700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.1984 - acc: 0.5400     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0894 - acc: 0.1700     \n",
      "Discriminator epoch 34\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.1182 - acc: 0.5300     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.0268 - acc: 0.5400     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1600     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0894 - acc: 0.1700     \n",
      "Discriminator epoch 35\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.1100 - acc: 0.4900     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.1765 - acc: 0.5200     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0888 - acc: 0.1600     \n",
      "Discriminator epoch 36\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.1745 - acc: 0.4600     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.1781 - acc: 0.4400     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0901 - acc: 0.1300     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0898 - acc: 0.1500     \n",
      "Discriminator epoch 37\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.0068 - acc: 0.5900     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.9771 - acc: 0.5300     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0927 - acc: 0.0800     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0913 - acc: 0.1400     \n",
      "Discriminator epoch 38\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.1544 - acc: 0.5200     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.1674 - acc: 0.5100     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0903 - acc: 0.1800     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0903 - acc: 0.1200     \n",
      "Discriminator epoch 39\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.9604 - acc: 0.6500     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.1133 - acc: 0.4800     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0906 - acc: 0.0800     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0903 - acc: 0.1100     \n",
      "Discriminator epoch 40\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.0393 - acc: 0.5800     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.9782 - acc: 0.5700     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0896 - acc: 0.1400     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0894 - acc: 0.1500     \n",
      "Discriminator epoch 41\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.1533 - acc: 0.5400     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.1249 - acc: 0.5000     \n",
      "Generator\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s - loss: 0.0894 - acc: 0.1700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0896 - acc: 0.1700     \n",
      "Discriminator epoch 42\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.0453 - acc: 0.5800     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.0519 - acc: 0.5300     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0904 - acc: 0.1000     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0896 - acc: 0.1200     \n",
      "Discriminator epoch 43\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.0381 - acc: 0.5300     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.0812 - acc: 0.5100     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0899 - acc: 0.1200     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0893 - acc: 0.1700     \n",
      "Discriminator epoch 44\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.2402 - acc: 0.4300     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.2717 - acc: 0.4100     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0900 - acc: 0.0800     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0896 - acc: 0.1600     \n",
      "Discriminator epoch 45\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.2090 - acc: 0.5400     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.0798 - acc: 0.5500     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0896 - acc: 0.1700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0893 - acc: 0.1700     \n",
      "Discriminator epoch 46\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.1540 - acc: 0.5100     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.9935 - acc: 0.5700     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0897 - acc: 0.1700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1900     \n",
      "Discriminator epoch 47\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.0049 - acc: 0.5800     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.0471 - acc: 0.5600     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0898 - acc: 0.1300     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1500     \n",
      "Discriminator epoch 48\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.8927 - acc: 0.6100     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.0502 - acc: 0.5400     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1800     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0894 - acc: 0.1600     \n",
      "Discriminator epoch 49\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.9139 - acc: 0.6500     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.0329 - acc: 0.5600     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0894 - acc: 0.1700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1600     \n",
      "Discriminator epoch 50\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.9588 - acc: 0.5400     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.0153 - acc: 0.5800     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0900 - acc: 0.1600     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0898 - acc: 0.1500     \n",
      "Discriminator epoch 51\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.1670 - acc: 0.5000     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.1137 - acc: 0.4900     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0898 - acc: 0.1500     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0894 - acc: 0.1700     \n",
      "Discriminator epoch 52\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.8844 - acc: 0.6600     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.1670 - acc: 0.5000     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0896 - acc: 0.1600     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0896 - acc: 0.1600     \n",
      "Discriminator epoch 53\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.8539 - acc: 0.6200     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.9514 - acc: 0.5800     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1700     \n",
      "Discriminator epoch 54\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.9034 - acc: 0.5900     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.9509 - acc: 0.6200     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0896 - acc: 0.1700     \n",
      "Discriminator epoch 55\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.0285 - acc: 0.5700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.0496 - acc: 0.5700     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0896 - acc: 0.1400     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0900 - acc: 0.1600     \n",
      "Discriminator epoch 56\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 1.1223 - acc: 0.5100     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.9671 - acc: 0.5800     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0894 - acc: 0.1700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0897 - acc: 0.1700     \n",
      "Discriminator epoch 57\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.9363 - acc: 0.5400     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.1212 - acc: 0.5500     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0896 - acc: 0.1700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1700     \n",
      "Discriminator epoch 58\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.9889 - acc: 0.5200     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.0527 - acc: 0.5300     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1600     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0896 - acc: 0.1600     \n",
      "Discriminator epoch 59\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.9159 - acc: 0.5700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 1.0937 - acc: 0.4600     \n",
      "Generator\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 0s - loss: 0.0895 - acc: 0.1700     \n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 0s - loss: 0.0896 - acc: 0.1600     \n"
     ]
    }
   ],
   "source": [
    "nb_epochs=2\n",
    "rate=5\n",
    "for i in range(0,n):\n",
    "    print('Discriminator epoch', i)\n",
    "    discriminator.fit(x_train_noisy,np.array(y_train),\n",
    "                    epochs=nb_epochs,\n",
    "                    batch_size=30,verbose=1)\n",
    "    print('Generator')\n",
    "    GAN.fit(x_train_noisy,np.array(y_train),\n",
    "            batch_size=30, epochs=nb_epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we reset all variables that were reshaped and one-hot encoded to calculate accuracy in training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "y_train=y_train[0:n]\n",
    "y_train=np.concatenate([y_train,y_train])[sel]\n",
    "y_test=y_test[0:n]\n",
    "y_test=np.concatenate([y_test,y_test])[sel]\n",
    "x_test_noisy=x_test_noisy[0:n]\n",
    "x_test_noisy=np.concatenate([x_test_noisy,x_test_noisy])[sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy Train:',1-np.count_nonzero(y_train-np.argmax(GAN.predict(x_train_noisy),axis=1))/n)\n",
    "\n",
    "print('Accuracy Test:',1-np.count_nonzero(y_test-np.argmax(GAN.predict(x_test_noisy),axis=1))/n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
